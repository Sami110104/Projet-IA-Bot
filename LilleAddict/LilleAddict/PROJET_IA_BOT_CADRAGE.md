# ğŸ¯ PROJET IA BOT - LILLE ADDICT
## Use Case 1 : "Que faire ce week-end Ã  Lille ?"

**Date :** 08/01/2026  
**DurÃ©e :** 7 jours  
**Groupe :** 3-5 personnes  

---

## ğŸ“‹ CONTEXTE

CrÃ©ation d'un agent conversationnel intelligent capable de recommander des Ã©vÃ©nements Ã  Lille en rÃ©pondant Ã  la question : **"Que faire ce week-end Ã  Lille ?"**

Le bot scrape les donnÃ©es de Lille Addict et rÃ©pond de maniÃ¨re naturelle aux requÃªtes utilisateur.

---

## ğŸ¯ OBJECTIF MVP

**User Story :**
> En tant qu'utilisateur, je veux demander "Que faire ce week-end Ã  Lille ?" et obtenir une liste d'Ã©vÃ©nements sympas avec les dÃ©tails pratiques.

**Exemple de conversation :**
```
User: Salut ! Que faire ce week-end Ã  Lille ?

Bot: Cette semaine Ã  Lille (du 22 au 28 dÃ©cembre), j'ai repÃ©rÃ© quelques Ã©vÃ©nements sympas :

ğŸª Cirque de NoÃ«l sur l'eau - jusqu'au 4 janvier
Un spectacle aquatique avec 15 artistes internationaux + le PÃ¨re NoÃ«l !
ğŸ“ Le ChapitÃ´, Lille Hellemmes
ğŸ’° Ã€ partir de 15â‚¬

ğŸ­ Festival NoÃ«l au thÃ©Ã¢tre - du 27 au 30 dÃ©cembre
6 spectacles pour toute la famille
ğŸ“ Le Zeppelin
ğŸ’° 5â‚¬

ğŸµ Concert de jazz - samedi 27
Le trio Musidora joue les classiques
ğŸ“ La Moulinette, Lille
ğŸ’° Prix libre

Tu veux plus d'infos sur un Ã©vÃ©nement en particulier ?
```

---

## ğŸ“Š DONNÃ‰ES Ã€ SCRAPER

### Source principale
**URL :** `https://lilleaddict.fr/que-faire-a-lille-ce-week-end/`

### Structure de la page

Chaque article hebdomadaire contient :

**1. En-tÃªte :**
- Titre : "Que faire Ã  Lille et aux alentours du [dates]"
- Date de publication
- Introduction rÃ©sumant la semaine

**2. Ã‰vÃ©nements (section par section) :**

Chaque Ã©vÃ©nement contient :
```
Titre de l'Ã©vÃ©nement
â”œâ”€â”€ Description (paragraphe texte)
â”œâ”€â”€ Dates (ex: "Jusqu'au dimanche 4 janvier" ou "Samedi 27")
â”œâ”€â”€ Horaires (ex: "20h30-23h")
â”œâ”€â”€ Prix (ex: "Ã€ partir de 15â‚¬" ou "Gratuit")
â”œâ”€â”€ Lieu (adresse complÃ¨te)
â”œâ”€â”€ Informations complÃ©mentaires (parking, rÃ©servation...)
â””â”€â”€ Images (optionnel)
```

**Exemple concret d'Ã©vÃ©nement extrait :**
```json
{
  "title": "Cirque de NoÃ«l sur l'eau",
  "description": "2h de spectacle aquatique avec 15 artistes internationaux...",
  "dates": "Jusqu'au dimanche 4 janvier",
  "price": "Ã€ partir de 15â‚¬",
  "location": "Le ChapitÃ´, 208 rue Faidherbe, Lille Hellemmes",
  "hours": "Variable selon sÃ©ances",
  "booking": "RÃ©servation en lien dans la bio",
  "category": "Spectacle"
}
```

---

## ğŸ› ï¸ ARCHITECTURE TECHNIQUE

### Stack obligatoire (selon Ã©noncÃ©)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FRONTEND                      â”‚
â”‚              (JavaScript / React)               â”‚
â”‚  Interface web avec chatbot intÃ©grÃ©             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ HTTP/WebSocket
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   BACKEND                       â”‚
â”‚                  (Python)                       â”‚
â”‚  Orchestrateur IA + Gestion MCP                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                   â”‚
         â”‚                   â–¼
         â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚          â”‚   MCP SERVER    â”‚
         â”‚          â”‚   (Python)      â”‚
         â”‚          â”‚                 â”‚
         â”‚          â”‚  Tools:         â”‚
         â”‚          â”‚  - Scraping     â”‚
         â”‚          â”‚  - Data parse   â”‚
         â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MODÃˆLE IA LOCAL                    â”‚
â”‚                 (Ollama)                        â”‚
â”‚  ComprÃ©hension langage naturel + DÃ©cision       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ COMPOSANTS DÃ‰TAILLÃ‰S

### 1. FRONTEND (JavaScript)

**ResponsabilitÃ©s :**
- Interface utilisateur (chat)
- Envoi des messages user vers backend
- Affichage des rÃ©ponses du bot
- Gestion de l'historique de conversation

**Technologies suggÃ©rÃ©es :**
- React / Vue.js / Vanilla JS
- Framework CSS (Tailwind, Bootstrap...)

**Exemple de requÃªte frontend â†’ backend :**
```javascript
// POST /api/chat
{
  "message": "Que faire ce week-end Ã  Lille ?",
  "conversation_id": "abc123"
}
```

---

### 2. BACKEND (Python)

**ResponsabilitÃ©s :**
- Recevoir les requÃªtes du frontend
- Envoyer le message Ã  Ollama pour analyse
- DÃ©cider si un tool MCP doit Ãªtre appelÃ©
- Orchestrer les appels MCP
- Retourner la rÃ©ponse formatÃ©e au frontend

**Structure suggÃ©rÃ©e :**
```
backend/
â”œâ”€â”€ main.py              # API Flask/FastAPI
â”œâ”€â”€ ollama_client.py     # Client Ollama
â”œâ”€â”€ mcp_client.py        # Client MCP
â””â”€â”€ config.py            # Configuration
```

**Flux backend :**
```python
1. User message â†’ Backend
2. Backend â†’ Ollama : "L'utilisateur demande quoi faire ce week-end"
3. Ollama â†’ Backend : "Je dois appeler le tool get_weekend_events()"
4. Backend â†’ MCP Server : appel get_weekend_events()
5. MCP Server â†’ Backend : donnÃ©es Ã©vÃ©nements
6. Backend â†’ Ollama : "Voici les donnÃ©es, formule une rÃ©ponse"
7. Ollama â†’ Backend : rÃ©ponse en langage naturel
8. Backend â†’ Frontend : rÃ©ponse finale
```

---

### 3. MCP SERVER (Python)

**ResponsabilitÃ© :**
- Exposer les tools que l'IA peut utiliser
- ExÃ©cuter le scraping
- Parser et structurer les donnÃ©es

**Tool principal Ã  implÃ©menter :**

```python
# Tool : get_weekend_events()

def get_weekend_events():
    """
    Scrape la page 'Que faire ce week-end' de Lille Addict
    et retourne une liste structurÃ©e d'Ã©vÃ©nements.
    
    Returns:
        dict: {
            "week_dates": "22 au 28 dÃ©cembre",
            "events": [
                {
                    "title": "Cirque de NoÃ«l sur l'eau",
                    "description": "...",
                    "dates": "Jusqu'au 4 janvier",
                    "price": "Ã€ partir de 15â‚¬",
                    "location": "Le ChapitÃ´, Lille",
                    ...
                },
                ...
            ]
        }
    """
```

**BibliothÃ¨ques Python suggÃ©rÃ©es :**
- `beautifulsoup4` : parsing HTML
- `requests` : requÃªtes HTTP
- `mcp` : SDK MCP Python (si disponible, sinon crÃ©er serveur custom)

**Structure MCP :**
```
mcp_server/
â”œâ”€â”€ server.py           # Serveur MCP
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ scraping.py     # Tool de scraping
â””â”€â”€ utils/
    â””â”€â”€ parser.py       # Parsing HTML
```

---

### 4. MODÃˆLE IA (Ollama)

**ResponsabilitÃ© :**
- Comprendre l'intention de l'utilisateur
- DÃ©cider quand appeler les tools
- GÃ©nÃ©rer des rÃ©ponses naturelles

**Configuration Ollama :**
- ModÃ¨le recommandÃ© : `llama3.2` ou `mistral` (lÃ©gers et performants)
- Installation : `ollama pull llama3.2`

**Prompt systÃ¨me suggÃ©rÃ© :**
```
Tu es un assistant pour les Ã©vÃ©nements Ã  Lille.
Quand l'utilisateur demande ce qu'il peut faire ce week-end,
utilise le tool get_weekend_events() pour rÃ©cupÃ©rer les Ã©vÃ©nements
et prÃ©sente-les de maniÃ¨re claire et attractive.

Sois concis, amical et mets en avant les infos pratiques (dates, prix, lieu).
```

---

## ğŸ“ EXEMPLE DE SCRAPING

### Page cible
`https://lilleaddict.fr/que-faire-a-lille-ce-week-end/que-faire-a-lille-et-aux-alentours-du-22-au-28-decembre.html`

### SÃ©lecteurs HTML (Ã  affiner avec inspection)

**Structure observÃ©e :**
- Chaque Ã©vÃ©nement est dans une section H2
- Informations dans des listes `<ul>` ou paragraphes `<p>`
- Prix/dates/lieux souvent en dÃ©but de section

**Pseudo-code scraping :**
```python
import requests
from bs4 import BeautifulSoup

def scrape_weekend_events(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
    
    events = []
    
    # Trouver tous les titres H2 (= Ã©vÃ©nements)
    event_sections = soup.find_all('h2')
    
    for section in event_sections:
        event = {
            'title': section.get_text().strip(),
            'description': '',
            'dates': '',
            'price': '',
            'location': ''
        }
        
        # Parser les infos aprÃ¨s le H2
        next_elements = section.find_next_siblings()
        
        for elem in next_elements:
            text = elem.get_text().strip()
            
            # Identifier dates, prix, lieu par mots-clÃ©s
            if 'jusqu\'au' in text.lower() or 'samedi' in text.lower():
                event['dates'] = text
            elif 'â‚¬' in text or 'gratuit' in text.lower():
                event['price'] = text
            elif 'rue' in text.lower() or 'avenue' in text.lower():
                event['location'] = text
            else:
                event['description'] += text + ' '
        
        events.append(event)
    
    return events
```

---

## âœ… CHECKLIST MVP

### Phase 1 : Setup (Jour 1-2)
- [ ] Installer Ollama + tÃ©lÃ©charger modÃ¨le
- [ ] CrÃ©er structure projet (frontend / backend / mcp)
- [ ] Tester requÃªte basique Ollama
- [ ] VÃ©rifier autorisation scraping (robots.txt âœ…)

### Phase 2 : Backend + MCP (Jour 2-4)
- [ ] CrÃ©er le tool MCP `get_weekend_events()`
- [ ] ImplÃ©menter le scraping BeautifulSoup
- [ ] Parser les donnÃ©es (titre, dates, prix, lieu)
- [ ] Tester le tool isolÃ©
- [ ] Connecter backend â†’ Ollama
- [ ] Connecter backend â†’ MCP

### Phase 3 : Frontend (Jour 4-5)
- [ ] Interface chat basique
- [ ] Connexion frontend â†’ backend
- [ ] Affichage rÃ©ponses bot
- [ ] Styling CSS

### Phase 4 : IntÃ©gration (Jour 6)
- [ ] Test flux complet : user â†’ bot â†’ scraping â†’ rÃ©ponse
- [ ] Ajustements prompt IA
- [ ] Gestion d'erreurs (site down, parsing fail...)

### Phase 5 : Documentation (Jour 7)
- [ ] SchÃ©ma d'architecture
- [ ] Explication flux de donnÃ©es
- [ ] Justification choix techniques
- [ ] Limites & amÃ©liorations

---

## ğŸš€ Ã‰VOLUTIONS FUTURES

**V2 - Filtres :**
- "Ã‰vÃ©nements gratuits ce week-end"
- "Spectacles pour enfants"
- "Concerts de jazz"

**V3 - MÃ©tÃ©o-aware :**
- IntÃ©grer API mÃ©tÃ©o
- Recommander intÃ©rieur/extÃ©rieur selon la mÃ©tÃ©o

**V4 - Multi-sources :**
- Scraper d'autres sites lillois
- AgrÃ©gateur d'Ã©vÃ©nements

---

## ğŸ“š RESSOURCES UTILES

**Ollama :**
- Documentation : https://ollama.ai/
- Models : https://ollama.ai/library

**MCP :**
- SpÃ©cification : https://github.com/modelcontextprotocol
- Python SDK : Ã  vÃ©rifier disponibilitÃ©

**Scraping Python :**
- BeautifulSoup : https://www.crummy.com/software/BeautifulSoup/
- Requests : https://requests.readthedocs.io/

**Site cible :**
- Lille Addict : https://lilleaddict.fr/
- Robots.txt : https://lilleaddict.fr/robots.txt âœ… AutorisÃ©

---

## ğŸ“ LIVRABLES ATTENDUS

1. **Application fonctionnelle**
   - Site web avec chatbot intÃ©grÃ©
   - Scraping rÃ©el (pas de mock data)
   - Flux complet frontend â†’ backend â†’ MCP â†’ IA

2. **Documentation technique** (15-20 pages)
   - Architecture globale + schÃ©mas
   - Description flux de donnÃ©es
   - Explication + justification choix technos
   - Fonctionnement du MCP
   - Limites + amÃ©liorations

3. **Soutenance** (20 minutes)
   - DÃ©mo live
   - Explication technique
   - Analyse critique
   - Tous les membres parlent

---

## ğŸ“Œ NOTES IMPORTANTES

- âœ… Scraping autorisÃ© (vÃ©rifiÃ© robots.txt)
- â±ï¸ Scraper Ã  faible frÃ©quence (pas de spam)
- ğŸ¯ Usage pÃ©dagogique uniquement
- ğŸš« Pas de modÃ¨le open-source local obligatoire (Ollama)
- ğŸ“¦ Pas de services tiers payants

---

**Prochaine Ã©tape :** Commencer par le setup Ollama + premier test de scraping ! ğŸš€
